"""
LLM OCR Module - OCR par Vision LLM

Utilise un LLM vision (GPT-4V, Claude Vision, DALLEM, etc.) pour extraire
le texte des pages PDF scann√©es ou de mauvaise qualit√©.

Fonctionnalit√©s:
- Conversion PDF vers images via PyMuPDF
- Envoi des images au LLM Vision
- Extraction de texte structur√©
- Mode fallback automatique si OCR classique √©choue
- Support natif de l'API DALLEM
- Mode OFFLINE avec Donut-base local
"""

import os
import io
import base64
import logging
import time
from typing import List, Dict, Any, Optional, Tuple, Callable
from dataclasses import dataclass

logger = logging.getLogger(__name__)

# Import du gestionnaire de configuration pour le mode offline
try:
    from core.config_manager import is_offline_mode
    CONFIG_MANAGER_AVAILABLE = True
except ImportError:
    CONFIG_MANAGER_AVAILABLE = False
    def is_offline_mode():
        return False

# Import de l'OCR offline (Donut-base)
OFFLINE_OCR_AVAILABLE = False
try:
    from core.offline_models import get_offline_ocr, OfflineOCR
    OFFLINE_OCR_AVAILABLE = True
except ImportError:
    pass

# =============================================================================
#  IMPORT CONFIGURATION DALLEM (optionnel)
# =============================================================================

try:
    from core.models_utils import (
        DALLEM_API_KEY,
        DALLEM_API_BASE,
        LLM_MODEL,
        create_http_client,
    )
    DALLEM_CONFIG_AVAILABLE = True
except ImportError:
    DALLEM_CONFIG_AVAILABLE = False
    DALLEM_API_KEY = None
    DALLEM_API_BASE = None
    LLM_MODEL = None

# =============================================================================
#  CONFIGURATION
# =============================================================================

# R√©solution pour la conversion PDF -> Image (DPI)
DEFAULT_DPI = 200  # 200 DPI pour meilleure qualit√© OCR

# Taille maximale d'image en pixels (redimensionner si plus grand)
MAX_IMAGE_SIZE = 2048

# Nombre maximum de pages √† traiter par appel
MAX_PAGES_PER_BATCH = 5

# Format d'image pour l'encodage
IMAGE_FORMAT = "PNG"

# Prompt syst√®me pour l'extraction OCR
OCR_SYSTEM_PROMPT = """Tu es un expert en OCR (reconnaissance optique de caract√®res).
Ta t√¢che est d'extraire le texte EXACT de l'image fournie.

Instructions:
1. Extrais TOUT le texte visible, sans rien ajouter ni modifier
2. Pr√©serve la structure (paragraphes, listes, tableaux)
3. Pour les tableaux, utilise des espaces ou | pour s√©parer les colonnes
4. Indique [illisible] pour les parties impossibles √† lire
5. Conserve les num√©ros, r√©f√©rences et codes exactement comme ils apparaissent
6. Si c'est un document r√©glementaire (EASA, FAA), fais tr√®s attention aux r√©f√©rences (CS xx.xxx, AMC, GM)

Retourne UNIQUEMENT le texte extrait, sans commentaires ni explications."""

# Prompt utilisateur pour l'OCR
OCR_USER_PROMPT = """Extrais le texte de cette image de document.
Pr√©serve la mise en page et la structure autant que possible.
Texte extrait:"""


# =============================================================================
#  DATA CLASSES
# =============================================================================

@dataclass
class OCRResult:
    """R√©sultat de l'OCR pour une page."""
    page_number: int
    text: str
    confidence: float  # 0-1 estimation de confiance
    processing_time: float  # secondes
    error: Optional[str] = None


@dataclass
class DocumentOCRResult:
    """R√©sultat de l'OCR pour un document complet."""
    total_pages: int
    processed_pages: int
    full_text: str
    page_results: List[OCRResult]
    total_time: float
    avg_confidence: float
    errors: List[str]


# =============================================================================
#  IMAGE UTILITIES
# =============================================================================

def detect_page_orientation(
    pdf_path: str,
    page_number: int,
    log=None
) -> int:
    """
    D√©tecte l'orientation d'une page PDF et retourne l'angle de correction.

    M√©thodes de d√©tection:
    1. Rotation metadata du PDF
    2. Analyse du texte existant (direction)
    3. Heuristique bas√©e sur l'aspect ratio

    Args:
        pdf_path: Chemin du fichier PDF
        page_number: Num√©ro de page (0-indexed)
        log: Logger

    Returns:
        Angle de rotation √† appliquer (0, 90, 180, 270) pour remettre droit
    """
    _log = log or logger

    try:
        import pymupdf as fitz
    except ImportError:
        try:
            import fitz
        except ImportError:
            return 0

    doc = None
    try:
        doc = fitz.open(pdf_path)
        if page_number >= len(doc):
            return 0

        page = doc[page_number]

        # 1. V√©rifier la rotation metadata de la page
        page_rotation = page.rotation
        if page_rotation != 0:
            _log.debug(f"[LLM-OCR] Page {page_number}: rotation metadata = {page_rotation}¬∞")
            # La rotation est d√©j√† g√©r√©e par PyMuPDF lors du rendu
            return 0

        # 2. Analyser le texte existant pour d√©tecter l'orientation
        # Extraire les blocs de texte avec leurs coordonn√©es
        text_dict = page.get_text("dict", flags=fitz.TEXT_PRESERVE_WHITESPACE)
        blocks = text_dict.get("blocks", [])

        text_blocks = [b for b in blocks if b.get("type") == 0]  # Type 0 = texte

        if text_blocks:
            # Analyser la direction dominante du texte
            orientation = _analyze_text_direction(text_blocks, page.rect, _log)
            if orientation != 0:
                _log.info(f"[LLM-OCR] Page {page_number}: orientation texte d√©tect√©e = {orientation}¬∞")
                return orientation

        # 3. Heuristique bas√©e sur l'aspect ratio (pour pages scann√©es sans texte d√©tectable)
        # Les documents A4/Letter sont g√©n√©ralement en portrait
        width = page.rect.width
        height = page.rect.height

        if width > height * 1.2:
            # Page en paysage - probablement tourn√©e de 90¬∞
            _log.debug(f"[LLM-OCR] Page {page_number}: aspect ratio sugg√®re rotation 90¬∞")
            # On ne corrige pas automatiquement car √ßa peut √™tre intentionnel
            # Retourner 0 et laisser l'utilisateur d√©cider

        return 0

    except Exception as e:
        _log.warning(f"[LLM-OCR] Erreur d√©tection orientation page {page_number}: {e}")
        return 0
    finally:
        if doc:
            doc.close()


def _analyze_text_direction(blocks: List[Dict], page_rect, log) -> int:
    """
    Analyse la direction du texte dans les blocs pour d√©tecter la rotation.

    Retourne l'angle de correction (0, 90, 180, 270).
    """
    if not blocks:
        return 0

    # Analyser les lignes de texte
    horizontal_count = 0
    vertical_count = 0
    upside_down_indicators = 0

    for block in blocks:
        for line in block.get("lines", []):
            # Calculer la direction de la ligne
            spans = line.get("spans", [])
            if not spans:
                continue

            # Bounding box de la ligne
            bbox = line.get("bbox", [0, 0, 0, 0])
            line_width = bbox[2] - bbox[0]
            line_height = bbox[3] - bbox[1]

            if line_width > line_height * 2:
                horizontal_count += 1
            elif line_height > line_width * 2:
                vertical_count += 1

            # V√©rifier si le texte est en haut ou en bas de la page
            # Le texte normal commence g√©n√©ralement en haut
            line_center_y = (bbox[1] + bbox[3]) / 2
            page_center_y = page_rect.height / 2

            # Si beaucoup de texte est en bas, possible rotation 180¬∞
            if line_center_y > page_center_y:
                upside_down_indicators += 1

    total_lines = horizontal_count + vertical_count

    if total_lines == 0:
        return 0

    # Si majorit√© de lignes verticales -> rotation 90¬∞ ou 270¬∞
    if vertical_count > horizontal_count * 2:
        log.debug(f"[LLM-OCR] Texte vertical d√©tect√© ({vertical_count} vs {horizontal_count} horizontal)")
        return 90  # Ou 270, difficile √† d√©terminer sans plus d'analyse

    return 0


def pdf_page_to_image(
    pdf_path: str,
    page_number: int,
    dpi: int = DEFAULT_DPI,
    max_size: int = MAX_IMAGE_SIZE,
    auto_rotate: bool = True,
    force_rotation: Optional[int] = None,
    log=None
) -> Optional[bytes]:
    """
    Convertit une page PDF en image PNG avec correction d'orientation.

    Args:
        pdf_path: Chemin du fichier PDF
        page_number: Num√©ro de page (0-indexed)
        dpi: R√©solution en DPI
        max_size: Taille maximale en pixels
        auto_rotate: Si True, d√©tecte et corrige l'orientation automatiquement
        force_rotation: Force une rotation sp√©cifique (0, 90, 180, 270)

    Returns:
        Image en bytes (PNG) ou None si erreur
    """
    _log = log or logger

    try:
        import pymupdf as fitz
    except ImportError:
        try:
            import fitz
        except ImportError:
            _log.error("[LLM-OCR] PyMuPDF non install√©")
            return None

    doc = None
    try:
        doc = fitz.open(pdf_path)

        if page_number >= len(doc):
            _log.warning(f"[LLM-OCR] Page {page_number} n'existe pas (max={len(doc)-1})")
            return None

        page = doc[page_number]

        # D√©terminer la rotation √† appliquer
        rotation = 0
        if force_rotation is not None:
            rotation = force_rotation % 360
            _log.debug(f"[LLM-OCR] Page {page_number}: rotation forc√©e = {rotation}¬∞")
        elif auto_rotate:
            rotation = detect_page_orientation(pdf_path, page_number, log=_log)

        # Calculer le zoom pour la r√©solution souhait√©e
        zoom = dpi / 72.0  # 72 DPI est la r√©solution par d√©faut des PDF

        # Matrice de transformation avec rotation
        mat = fitz.Matrix(zoom, zoom)

        if rotation != 0:
            # Appliquer la rotation autour du centre de la page
            # PyMuPDF: rotation positive = sens horaire
            mat = mat.prerotate(rotation)
            _log.info(f"[LLM-OCR] Page {page_number}: rotation appliqu√©e = {rotation}¬∞")

        # Rendre la page en pixmap
        pix = page.get_pixmap(matrix=mat)

        # Redimensionner si n√©cessaire
        if pix.width > max_size or pix.height > max_size:
            scale = min(max_size / pix.width, max_size / pix.height)

            # Recr√©er avec le bon scale
            mat_scaled = fitz.Matrix(zoom * scale, zoom * scale)
            if rotation != 0:
                mat_scaled = mat_scaled.prerotate(rotation)
            pix = page.get_pixmap(matrix=mat_scaled)

        # Convertir en PNG bytes
        png_bytes = pix.tobytes("png")

        _log.debug(f"[LLM-OCR] Page {page_number}: {pix.width}x{pix.height} pixels")

        return png_bytes

    except Exception as e:
        _log.error(f"[LLM-OCR] Erreur conversion page {page_number}: {e}")
        return None
    finally:
        if doc:
            doc.close()


def detect_orientation_with_llm(
    image_bytes: bytes,
    http_client,
    api_key: str,
    api_base: str,
    model: str,
    log=None
) -> int:
    """
    Utilise le LLM Vision pour d√©tecter l'orientation d'une image.

    Fait un appel r√©seau suppl√©mentaire mais tr√®s fiable.

    Args:
        image_bytes: Image en bytes
        http_client: Client HTTP
        api_key: Cl√© API
        api_base: URL de base
        model: Mod√®le vision

    Returns:
        Angle de rotation pour corriger (0, 90, 180, 270)
    """
    _log = log or logger

    orientation_prompt = """Analyse cette image de document.
D√©termine si le document est correctement orient√© pour la lecture.

R√©ponds UNIQUEMENT par un nombre:
- 0 si le document est droit (texte lisible normalement)
- 90 si le document est tourn√© de 90¬∞ dans le sens horaire (texte vertical, t√™te √† droite)
- 180 si le document est √† l'envers (texte invers√©)
- 270 si le document est tourn√© de 90¬∞ dans le sens anti-horaire (texte vertical, t√™te √† gauche)

R√©ponds uniquement par le nombre, sans explication."""

    image_b64 = image_to_base64(image_bytes)

    url = api_base.rstrip("/") + "/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": orientation_prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_b64}",
                            "detail": "low"  # Basse r√©solution suffit pour orientation
                        }
                    }
                ]
            }
        ],
        "temperature": 0,
        "max_tokens": 10,
    }

    try:
        resp = http_client.post(url, headers=headers, json=payload, timeout=30.0)
        resp.raise_for_status()
        data = resp.json()

        content = data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()

        # Parser la r√©ponse
        for angle in [0, 90, 180, 270]:
            if str(angle) in content:
                _log.info(f"[LLM-OCR] Orientation d√©tect√©e par LLM: {angle}¬∞")
                return angle

        _log.warning(f"[LLM-OCR] R√©ponse orientation non parsable: {content}")
        return 0

    except Exception as e:
        _log.warning(f"[LLM-OCR] Erreur d√©tection orientation LLM: {e}")
        return 0


def image_to_base64(image_bytes: bytes) -> str:
    """Encode une image en base64."""
    return base64.b64encode(image_bytes).decode('utf-8')


def get_pdf_page_count(pdf_path: str, log=None) -> int:
    """Retourne le nombre de pages d'un PDF."""
    _log = log or logger

    try:
        import pymupdf as fitz
    except ImportError:
        try:
            import fitz
        except ImportError:
            _log.error("[LLM-OCR] PyMuPDF non install√©")
            return 0

    doc = None
    try:
        doc = fitz.open(pdf_path)
        return len(doc)
    except Exception as e:
        _log.error(f"[LLM-OCR] Erreur lecture PDF: {e}")
        return 0
    finally:
        if doc:
            doc.close()


# =============================================================================
#  LLM VISION OCR
# =============================================================================

def ocr_image_with_llm(
    image_bytes: bytes,
    http_client,
    api_key: str,
    api_base: str,
    model: str,
    system_prompt: str = OCR_SYSTEM_PROMPT,
    user_prompt: str = OCR_USER_PROMPT,
    log=None
) -> Tuple[str, float]:
    """
    Extrait le texte d'une image via LLM Vision.

    Args:
        image_bytes: Image en bytes
        http_client: Client HTTP
        api_key: Cl√© API
        api_base: URL de base de l'API
        model: Nom du mod√®le vision
        system_prompt: Prompt syst√®me
        user_prompt: Prompt utilisateur
        log: Logger

    Returns:
        (texte extrait, estimation de confiance)
    """
    _log = log or logger

    # Encoder l'image en base64
    image_b64 = image_to_base64(image_bytes)

    # Construire la requ√™te pour l'API Vision
    # Format compatible OpenAI Vision API
    url = api_base.rstrip("/") + "/chat/completions"

    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    # Message avec image (format OpenAI Vision)
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": user_prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_b64}",
                            "detail": "high"  # Haute r√©solution pour OCR
                        }
                    }
                ]
            }
        ],
        "temperature": 0.1,  # Basse temp√©rature pour extraction pr√©cise
        "max_tokens": 4096,  # Assez pour une page compl√®te
    }

    try:
        resp = http_client.post(url, headers=headers, json=payload, timeout=120.0)
        resp.raise_for_status()
        data = resp.json()

        content = data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()

        if not content:
            _log.warning("[LLM-OCR] R√©ponse vide du LLM")
            return "", 0.0

        # Estimation de confiance bas√©e sur la longueur et le contenu
        confidence = _estimate_ocr_confidence(content)

        _log.debug(f"[LLM-OCR] Texte extrait: {len(content)} chars, confiance: {confidence:.0%}")

        return content, confidence

    except Exception as e:
        _log.error(f"[LLM-OCR] Erreur appel LLM Vision: {e}")
        return "", 0.0


def _estimate_ocr_confidence(text: str) -> float:
    """
    Estime la confiance de l'OCR bas√©e sur le texte extrait.

    Heuristiques:
    - Texte trop court = faible confiance
    - Beaucoup de [illisible] = faible confiance
    - Ratio de mots reconnaissables
    """
    if not text:
        return 0.0

    confidence = 1.0

    # P√©nalit√© pour texte court
    if len(text) < 100:
        confidence -= 0.3
    elif len(text) < 500:
        confidence -= 0.1

    # P√©nalit√© pour sections illisibles
    illisible_count = text.lower().count("[illisible]")
    if illisible_count > 0:
        confidence -= min(0.4, illisible_count * 0.1)

    # V√©rifier le ratio de caract√®res alphab√©tiques
    alpha_count = sum(1 for c in text if c.isalpha())
    alpha_ratio = alpha_count / len(text) if text else 0

    if alpha_ratio < 0.3:
        confidence -= 0.2

    return max(0.0, min(1.0, confidence))


# =============================================================================
#  DOCUMENT OCR
# =============================================================================

def _format_duration(seconds: float) -> str:
    """Formate une dur√©e en secondes en format lisible."""
    if seconds < 60:
        return f"{seconds:.1f}s"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes}m{secs:02d}s"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}h{minutes:02d}m"


def _print_progress_bar(current: int, total: int, width: int = 40, prefix: str = "") -> None:
    """Affiche une barre de progression textuelle."""
    if total == 0:
        return
    percent = current / total
    filled = int(width * percent)
    bar = "‚ñà" * filled + "‚ñë" * (width - filled)
    print(f"\r  {prefix}[{bar}] {current}/{total} ({percent*100:.0f}%)", end="", flush=True)


def ocr_pdf_with_llm(
    pdf_path: str,
    http_client,
    api_key: str,
    api_base: str,
    model: str,
    pages: Optional[List[int]] = None,
    dpi: int = DEFAULT_DPI,
    auto_rotate: bool = True,
    smart_rotate: bool = True,
    progress_cb: Optional[Callable[[float, str], None]] = None,
    log=None
) -> DocumentOCRResult:
    """
    Effectue l'OCR d'un PDF complet via LLM Vision.

    Args:
        pdf_path: Chemin du fichier PDF
        http_client: Client HTTP
        api_key: Cl√© API
        api_base: URL de base de l'API
        model: Nom du mod√®le vision
        pages: Liste des pages √† traiter (None = toutes)
        dpi: R√©solution pour la conversion
        auto_rotate: Si True, corrige l'orientation automatiquement (local)
        smart_rotate: Si True et auto_rotate √©choue, utilise LLM pour d√©tecter
                      l'orientation (ajoute 1 appel r√©seau par page scann√©e)
        progress_cb: Callback de progression (ratio, message)
        log: Logger

    Returns:
        DocumentOCRResult avec le texte extrait
    """
    _log = log or logger
    start_time = time.time()

    # Obtenir le nombre de pages
    total_pages = get_pdf_page_count(pdf_path, log=_log)

    if total_pages == 0:
        return DocumentOCRResult(
            total_pages=0,
            processed_pages=0,
            full_text="",
            page_results=[],
            total_time=0,
            avg_confidence=0,
            errors=["Impossible de lire le PDF"]
        )

    # D√©terminer les pages √† traiter
    if pages is None:
        pages_to_process = list(range(total_pages))
    else:
        pages_to_process = [p for p in pages if 0 <= p < total_pages]

    # Affichage du d√©marrage OCR LLM
    import os
    filename = os.path.basename(pdf_path)
    print(f"\n{'='*60}")
    print(f"üîç OCR LLM VISION - D√âMARRAGE")
    print(f"{'='*60}")
    print(f"  üìÑ Fichier: {filename}")
    print(f"  üìñ Pages √† traiter: {len(pages_to_process)}/{total_pages}")
    print(f"  üéØ R√©solution: {dpi} DPI")
    print(f"  üîÑ Auto-rotation: {'‚úÖ Oui' if auto_rotate else '‚ùå Non'}")
    print(f"  ü§ñ Smart rotation (LLM): {'‚úÖ Oui' if smart_rotate else '‚ùå Non'}")
    print(f"{'‚îÄ'*60}")

    _log.info(f"[LLM-OCR] D√©marrage OCR: {len(pages_to_process)}/{total_pages} pages")
    _log.info(f"[LLM-OCR] Options: auto_rotate={auto_rotate}, smart_rotate={smart_rotate}")

    page_results: List[OCRResult] = []
    errors: List[str] = []
    all_texts: List[str] = []

    for i, page_num in enumerate(pages_to_process):
        page_start = time.time()

        # Callback de progression
        if progress_cb:
            progress = (i + 1) / len(pages_to_process)
            progress_cb(progress, f"OCR page {page_num + 1}/{total_pages}")

        # Afficher la barre de progression
        _print_progress_bar(i, len(pages_to_process), prefix="üìÑ ")

        _log.info(f"[LLM-OCR] Traitement page {page_num + 1}/{total_pages}...")

        # Convertir la page en image (avec auto-rotation locale si activ√©e)
        image_bytes = pdf_page_to_image(
            pdf_path, page_num,
            dpi=dpi,
            auto_rotate=auto_rotate,
            log=_log
        )

        if not image_bytes:
            error_msg = f"Erreur conversion page {page_num + 1}"
            errors.append(error_msg)
            page_results.append(OCRResult(
                page_number=page_num + 1,
                text="",
                confidence=0.0,
                processing_time=time.time() - page_start,
                error=error_msg
            ))
            continue

        # Smart rotation: d√©tecter l'orientation par LLM si n√©cessaire
        # (pour les PDF scann√©s o√π la d√©tection locale ne fonctionne pas)
        if smart_rotate:
            # V√©rifier si la page semble √™tre une image scann√©e (pas de texte d√©tect√©)
            local_rotation = detect_page_orientation(pdf_path, page_num, log=_log)

            if local_rotation == 0:
                # La d√©tection locale n'a rien trouv√©, utiliser LLM
                _log.debug(f"[LLM-OCR] Page {page_num + 1}: d√©tection orientation par LLM...")
                llm_rotation = detect_orientation_with_llm(
                    image_bytes=image_bytes,
                    http_client=http_client,
                    api_key=api_key,
                    api_base=api_base,
                    model=model,
                    log=_log
                )

                if llm_rotation != 0:
                    # Re-g√©n√©rer l'image avec la bonne rotation
                    _log.info(f"[LLM-OCR] Page {page_num + 1}: correction rotation {llm_rotation}¬∞")
                    image_bytes = pdf_page_to_image(
                        pdf_path, page_num,
                        dpi=dpi,
                        auto_rotate=False,
                        force_rotation=llm_rotation,
                        log=_log
                    )

                    if not image_bytes:
                        error_msg = f"Erreur rotation page {page_num + 1}"
                        errors.append(error_msg)
                        page_results.append(OCRResult(
                            page_number=page_num + 1,
                            text="",
                            confidence=0.0,
                            processing_time=time.time() - page_start,
                            error=error_msg
                        ))
                        continue

        # OCR via LLM
        text, confidence = ocr_image_with_llm(
            image_bytes=image_bytes,
            http_client=http_client,
            api_key=api_key,
            api_base=api_base,
            model=model,
            log=_log
        )

        processing_time = time.time() - page_start

        if text:
            all_texts.append(f"--- Page {page_num + 1} ---\n{text}")
            page_results.append(OCRResult(
                page_number=page_num + 1,
                text=text,
                confidence=confidence,
                processing_time=processing_time
            ))
            _log.info(
                f"[LLM-OCR] Page {page_num + 1}: {len(text)} chars, "
                f"confiance={confidence:.0%}, temps={processing_time:.1f}s"
            )
        else:
            error_msg = f"OCR √©chou√© page {page_num + 1}"
            errors.append(error_msg)
            page_results.append(OCRResult(
                page_number=page_num + 1,
                text="",
                confidence=0.0,
                processing_time=processing_time,
                error=error_msg
            ))

    # Barre de progression finale
    _print_progress_bar(len(pages_to_process), len(pages_to_process), prefix="üìÑ ")
    print()  # Nouvelle ligne apr√®s la barre

    # Calculer les statistiques
    total_time = time.time() - start_time
    processed_pages = sum(1 for r in page_results if r.text)
    confidences = [r.confidence for r in page_results if r.confidence > 0]
    avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0

    # Assembler le texte complet
    full_text = "\n\n".join(all_texts)

    # Affichage du r√©sum√© final
    print(f"{'‚îÄ'*60}")
    print(f"‚úÖ OCR LLM TERMIN√â")
    print(f"{'‚îÄ'*60}")
    print(f"  üìñ Pages trait√©es: {processed_pages}/{len(pages_to_process)}")
    if errors:
        print(f"  ‚ùå Erreurs: {len(errors)}")
    print(f"  üìä Confiance moyenne: {avg_confidence:.0%}")
    print(f"  üìù Caract√®res extraits: {len(full_text):,}")
    print(f"  ‚è±Ô∏è  Temps total: {_format_duration(total_time)}")
    if processed_pages > 0:
        print(f"  ‚ö° Temps moyen/page: {_format_duration(total_time / processed_pages)}")
    print(f"{'='*60}\n")

    _log.info(
        f"[LLM-OCR] Termin√©: {processed_pages}/{len(pages_to_process)} pages, "
        f"confiance={avg_confidence:.0%}, temps={total_time:.1f}s"
    )

    return DocumentOCRResult(
        total_pages=total_pages,
        processed_pages=processed_pages,
        full_text=full_text,
        page_results=page_results,
        total_time=total_time,
        avg_confidence=avg_confidence,
        errors=errors
    )


# =============================================================================
#  SMART OCR (FALLBACK AUTOMATIQUE)
# =============================================================================

def smart_ocr_pdf(
    pdf_path: str,
    http_client,
    api_key: str,
    api_base: str,
    model: str,
    quality_threshold: float = 0.5,
    fallback_pages_only: bool = True,
    auto_rotate: bool = True,
    smart_rotate: bool = True,
    progress_cb: Optional[Callable[[float, str], None]] = None,
    log=None
) -> Dict[str, Any]:
    """
    OCR intelligent avec fallback automatique.

    1. Tente l'extraction classique (PyMuPDF/pdfminer)
    2. √âvalue la qualit√© de chaque page
    3. Utilise LLM OCR uniquement pour les pages de mauvaise qualit√©
    4. Corrige l'orientation des pages si n√©cessaire

    Args:
        pdf_path: Chemin du PDF
        http_client: Client HTTP
        api_key: Cl√© API
        api_base: URL de base de l'API
        model: Mod√®le vision
        quality_threshold: Seuil en dessous duquel on utilise LLM OCR
        fallback_pages_only: Si True, ne traite que les pages de mauvaise qualit√©
        auto_rotate: Si True, d√©tection/correction locale de l'orientation
        smart_rotate: Si True, utilise LLM pour d√©tecter l'orientation si local √©choue
        progress_cb: Callback de progression
        log: Logger

    Returns:
        Dict avec texte final et m√©tadonn√©es
    """
    _log = log or logger

    # Import des fonctions de qualit√©
    try:
        from processing.pdf_processing import (
            extract_text_from_pdf,
            assess_extraction_quality
        )
    except ImportError:
        _log.error("[LLM-OCR] Impossible d'importer pdf_processing")
        return {"error": "Module pdf_processing non disponible"}

    import os
    filename = os.path.basename(pdf_path)
    total_pages = get_pdf_page_count(pdf_path, log=_log)

    print(f"\n{'='*60}")
    print(f"üî¨ SMART OCR - ANALYSE DE QUALIT√â")
    print(f"{'='*60}")
    print(f"  üìÑ Fichier: {filename}")
    print(f"  üìñ Pages: {total_pages}")
    print(f"  üéØ Seuil qualit√©: {quality_threshold:.0%}")
    print(f"{'‚îÄ'*60}")

    _log.info(f"[SMART-OCR] Analyse du PDF: {pdf_path}")

    # 1. Extraction classique
    print(f"  ‚è≥ Extraction classique en cours...")
    if progress_cb:
        progress_cb(0.1, "Extraction classique du texte...")

    try:
        classic_text = extract_text_from_pdf(pdf_path)
    except Exception as e:
        _log.warning(f"[SMART-OCR] Extraction classique √©chou√©e: {e}")
        classic_text = ""

    # 2. √âvaluer la qualit√© globale
    print(f"  ‚è≥ √âvaluation de la qualit√©...")
    if progress_cb:
        progress_cb(0.2, "√âvaluation de la qualit√©...")

    quality = assess_extraction_quality(classic_text)
    quality_score = quality.get("quality_score", 0) if quality else 0

    # Afficher le r√©sultat de l'√©valuation
    quality_icon = "‚úÖ" if quality_score >= quality_threshold else "‚ö†Ô∏è"
    print(f"  {quality_icon} Qualit√© extraction: {quality_score:.0%} (seuil: {quality_threshold:.0%})")
    print(f"  üìù Caract√®res extraits: {len(classic_text):,}")

    _log.info(f"[SMART-OCR] Qualit√© extraction classique: {quality_score:.0%}")

    # Si la qualit√© est bonne, retourner le texte classique
    if quality_score >= quality_threshold:
        print(f"{'‚îÄ'*60}")
        print(f"  ‚úÖ Qualit√© suffisante - pas besoin d'OCR LLM")
        print(f"{'='*60}\n")
        _log.info("[SMART-OCR] Qualit√© suffisante, pas besoin de LLM OCR")
        return {
            "text": classic_text,
            "method": "classic",
            "quality_score": quality_score,
            "llm_ocr_used": False,
            "pages_ocr": 0,
        }

    # 3. Utiliser LLM OCR
    print(f"{'‚îÄ'*60}")
    print(f"  ‚ö†Ô∏è Qualit√© insuffisante ‚Üí lancement OCR LLM Vision")
    print(f"{'‚îÄ'*60}")
    _log.info(f"[SMART-OCR] Qualit√© insuffisante ({quality_score:.0%}), utilisation LLM OCR...")

    if progress_cb:
        progress_cb(0.3, "D√©marrage OCR LLM Vision...")

    # D√©terminer les pages √† traiter
    if fallback_pages_only:
        # TODO: √âvaluer la qualit√© page par page et ne traiter que les mauvaises
        # Pour l'instant, on traite tout si la qualit√© globale est mauvaise
        pages = None
    else:
        pages = None

    # OCR avec progression ajust√©e
    def ocr_progress(ratio, msg):
        if progress_cb:
            # Mapper 0-1 sur 0.3-0.95
            adjusted = 0.3 + ratio * 0.65
            progress_cb(adjusted, msg)

    ocr_result = ocr_pdf_with_llm(
        pdf_path=pdf_path,
        http_client=http_client,
        api_key=api_key,
        api_base=api_base,
        model=model,
        pages=pages,
        auto_rotate=auto_rotate,
        smart_rotate=smart_rotate,
        progress_cb=ocr_progress,
        log=_log
    )

    if progress_cb:
        progress_cb(1.0, "OCR termin√©")

    # Choisir le meilleur r√©sultat
    if ocr_result.avg_confidence > quality_score:
        final_text = ocr_result.full_text
        method = "llm_ocr"
    else:
        # Si l'OCR LLM n'est pas meilleur, garder le classique
        final_text = classic_text
        method = "classic_preferred"

    return {
        "text": final_text,
        "method": method,
        "quality_score": quality_score,
        "llm_ocr_used": True,
        "llm_ocr_confidence": ocr_result.avg_confidence,
        "pages_ocr": ocr_result.processed_pages,
        "total_pages": ocr_result.total_pages,
        "ocr_time": ocr_result.total_time,
        "ocr_errors": ocr_result.errors,
    }


# =============================================================================
#  UTILITY FUNCTIONS
# =============================================================================

def ocr_single_page(
    pdf_path: str,
    page_number: int,
    http_client,
    api_key: str,
    api_base: str,
    model: str,
    dpi: int = DEFAULT_DPI,
    log=None
) -> OCRResult:
    """
    OCR d'une seule page via LLM Vision.

    Utile pour tester ou traiter des pages sp√©cifiques.

    Args:
        pdf_path: Chemin du PDF
        page_number: Num√©ro de page (1-indexed pour l'utilisateur)
        http_client: Client HTTP
        api_key: Cl√© API
        api_base: URL API
        model: Mod√®le vision
        dpi: R√©solution
        log: Logger

    Returns:
        OCRResult pour cette page
    """
    _log = log or logger
    start_time = time.time()

    # Convertir en 0-indexed
    page_idx = page_number - 1

    # Convertir la page en image
    image_bytes = pdf_page_to_image(pdf_path, page_idx, dpi=dpi, log=_log)

    if not image_bytes:
        return OCRResult(
            page_number=page_number,
            text="",
            confidence=0.0,
            processing_time=time.time() - start_time,
            error="Erreur conversion page en image"
        )

    # OCR via LLM
    text, confidence = ocr_image_with_llm(
        image_bytes=image_bytes,
        http_client=http_client,
        api_key=api_key,
        api_base=api_base,
        model=model,
        log=_log
    )

    return OCRResult(
        page_number=page_number,
        text=text,
        confidence=confidence,
        processing_time=time.time() - start_time,
        error=None if text else "OCR n'a retourn√© aucun texte"
    )


def is_vision_model_available(
    http_client,
    api_key: str,
    api_base: str,
    model: str,
    log=None
) -> bool:
    """
    V√©rifie si le mod√®le vision est disponible et fonctionnel.

    Args:
        http_client: Client HTTP
        api_key: Cl√© API
        api_base: URL API
        model: Nom du mod√®le

    Returns:
        True si le mod√®le vision est disponible
    """
    _log = log or logger

    # Cr√©er une petite image de test (1x1 pixel blanc)
    test_image = base64.b64encode(
        # PNG 1x1 pixel blanc (plus petit PNG valide)
        b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01'
        b'\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\x0cIDATx\x9cc\xf8\xff'
        b'\xff?\x00\x05\xfe\x02\xfe\xdc\xccY\xe7\x00\x00\x00\x00IEND\xaeB`\x82'
    ).decode('utf-8')

    url = api_base.rstrip("/") + "/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "Test"},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{test_image}"}
                    }
                ]
            }
        ],
        "max_tokens": 10,
    }

    try:
        resp = http_client.post(url, headers=headers, json=payload, timeout=30.0)

        if resp.status_code == 200:
            _log.info(f"[LLM-OCR] Mod√®le vision {model} disponible")
            return True
        else:
            _log.warning(f"[LLM-OCR] Mod√®le vision {model} non disponible: {resp.status_code}")
            return False

    except Exception as e:
        _log.warning(f"[LLM-OCR] Test mod√®le vision √©chou√©: {e}")
        return False


# =============================================================================
#  FONCTIONS DE COMMODIT√â DALLEM
# =============================================================================

def ocr_pdf_with_dallem(
    pdf_path: str,
    pages: Optional[List[int]] = None,
    dpi: int = DEFAULT_DPI,
    auto_rotate: bool = True,
    smart_rotate: bool = True,
    progress_cb: Optional[Callable[[float, str], None]] = None,
    log=None
) -> DocumentOCRResult:
    """
    OCR d'un PDF en utilisant l'API DALLEM configur√©e.

    Utilise automatiquement les credentials DALLEM depuis models_utils.py.
    D√©tecte et corrige automatiquement l'orientation des pages scann√©es.

    Args:
        pdf_path: Chemin du fichier PDF
        pages: Liste des pages √† traiter (None = toutes)
        dpi: R√©solution pour la conversion
        auto_rotate: Si True, corrige l'orientation avec d√©tection locale (gratuit)
        smart_rotate: Si True, utilise DALLEM pour d√©tecter l'orientation des pages
                      scann√©es quand la d√©tection locale √©choue (+1 appel/page)
        progress_cb: Callback de progression
        log: Logger

    Returns:
        DocumentOCRResult avec le texte extrait

    Raises:
        RuntimeError: Si la configuration DALLEM n'est pas disponible

    Note:
        Appels r√©seau par page:
        - smart_rotate=False: 1 appel (OCR uniquement)
        - smart_rotate=True: 1-2 appels (d√©tection orientation + OCR)
    """
    _log = log or logger

    if not DALLEM_CONFIG_AVAILABLE:
        raise RuntimeError(
            "Configuration DALLEM non disponible. "
            "V√©rifiez que models_utils.py est accessible et configur√©."
        )

    _log.info(f"[LLM-OCR] OCR avec DALLEM: {pdf_path}")
    _log.info(f"[LLM-OCR] API: {DALLEM_API_BASE}, Model: {LLM_MODEL}")
    _log.info(f"[LLM-OCR] Rotation: auto={auto_rotate}, smart={smart_rotate}")

    http_client = create_http_client()

    return ocr_pdf_with_llm(
        pdf_path=pdf_path,
        http_client=http_client,
        api_key=DALLEM_API_KEY,
        api_base=DALLEM_API_BASE,
        model=LLM_MODEL,
        pages=pages,
        dpi=dpi,
        auto_rotate=auto_rotate,
        smart_rotate=smart_rotate,
        progress_cb=progress_cb,
        log=_log
    )


def smart_ocr_with_dallem(
    pdf_path: str,
    quality_threshold: float = 0.5,
    fallback_pages_only: bool = True,
    auto_rotate: bool = True,
    smart_rotate: bool = True,
    progress_cb: Optional[Callable[[float, str], None]] = None,
    log=None
) -> Dict[str, Any]:
    """
    OCR intelligent avec DALLEM et fallback automatique.

    1. Tente l'extraction classique (PyMuPDF/pdfminer)
    2. √âvalue la qualit√©
    3. Utilise DALLEM OCR si qualit√© < threshold
    4. Corrige automatiquement l'orientation des pages

    Args:
        pdf_path: Chemin du PDF
        quality_threshold: Seuil de qualit√© (0-1)
        fallback_pages_only: Si True, ne traite que les pages de mauvaise qualit√©
        auto_rotate: Si True, d√©tection locale de l'orientation (gratuit)
        smart_rotate: Si True, d√©tection par LLM si locale √©choue (+1 appel/page)
        progress_cb: Callback de progression
        log: Logger

    Returns:
        Dict avec texte et m√©tadonn√©es

    Example:
        >>> result = smart_ocr_with_dallem("document_scanne.pdf", quality_threshold=0.5)
        >>> print(f"M√©thode: {result['method']}, LLM utilis√©: {result['llm_ocr_used']}")
    """
    _log = log or logger

    if not DALLEM_CONFIG_AVAILABLE:
        raise RuntimeError(
            "Configuration DALLEM non disponible. "
            "V√©rifiez que models_utils.py est accessible et configur√©."
        )

    _log.info(f"[LLM-OCR] Smart OCR avec DALLEM: {pdf_path}")

    http_client = create_http_client()

    return smart_ocr_pdf(
        pdf_path=pdf_path,
        http_client=http_client,
        api_key=DALLEM_API_KEY,
        api_base=DALLEM_API_BASE,
        model=LLM_MODEL,
        quality_threshold=quality_threshold,
        fallback_pages_only=fallback_pages_only,
        auto_rotate=auto_rotate,
        smart_rotate=smart_rotate,
        progress_cb=progress_cb,
        log=_log
    )


def check_dallem_vision_available(log=None) -> bool:
    """
    V√©rifie si DALLEM est disponible et supporte les images.

    Returns:
        True si DALLEM Vision est disponible

    Example:
        >>> if check_dallem_vision_available():
        ...     result = smart_ocr_with_dallem("scan.pdf")
    """
    _log = log or logger

    if not DALLEM_CONFIG_AVAILABLE:
        _log.warning("[LLM-OCR] Configuration DALLEM non disponible")
        return False

    _log.info(f"[LLM-OCR] Test DALLEM Vision: {DALLEM_API_BASE}")

    http_client = create_http_client()

    return is_vision_model_available(
        http_client=http_client,
        api_key=DALLEM_API_KEY,
        api_base=DALLEM_API_BASE,
        model=LLM_MODEL,
        log=_log
    )


# =============================================================================
#  MODE OFFLINE - OCR AVEC DONUT-BASE LOCAL
# =============================================================================

def ocr_image_offline(
    image_bytes: bytes,
    log=None
) -> Tuple[str, float]:
    """
    Extrait le texte d'une image en mode offline avec Donut-base.

    Args:
        image_bytes: Image en bytes (PNG)
        log: Logger

    Returns:
        (texte extrait, estimation de confiance)
    """
    _log = log or logger

    if not OFFLINE_OCR_AVAILABLE:
        _log.error("[OFFLINE-OCR] Module offline non disponible")
        return "", 0.0

    try:
        from PIL import Image
        import io

        # Convertir les bytes en image PIL
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

        # Obtenir le client OCR offline
        ocr_client = get_offline_ocr(log=_log)

        # Extraire le texte
        text = ocr_client.extract_text(image)

        # Estimer la confiance
        confidence = _estimate_ocr_confidence(text)

        _log.debug(f"[OFFLINE-OCR] Texte extrait: {len(text)} chars, confiance: {confidence:.0%}")

        return text, confidence

    except Exception as e:
        _log.error(f"[OFFLINE-OCR] Erreur: {e}")
        return "", 0.0


def ocr_pdf_offline(
    pdf_path: str,
    pages: Optional[List[int]] = None,
    dpi: int = DEFAULT_DPI,
    progress_cb: Optional[Callable[[float, str], None]] = None,
    log=None
) -> DocumentOCRResult:
    """
    OCR d'un PDF complet en mode offline avec Donut-base.

    Args:
        pdf_path: Chemin du fichier PDF
        pages: Liste des pages a traiter (None = toutes)
        dpi: Resolution pour la conversion
        progress_cb: Callback de progression
        log: Logger

    Returns:
        DocumentOCRResult avec le texte extrait
    """
    _log = log or logger
    start_time = time.time()

    if not OFFLINE_OCR_AVAILABLE:
        return DocumentOCRResult(
            total_pages=0,
            processed_pages=0,
            full_text="",
            page_results=[],
            total_time=0,
            avg_confidence=0,
            errors=["Module OCR offline non disponible"]
        )

    # Obtenir le nombre de pages
    total_pages = get_pdf_page_count(pdf_path, log=_log)

    if total_pages == 0:
        return DocumentOCRResult(
            total_pages=0,
            processed_pages=0,
            full_text="",
            page_results=[],
            total_time=0,
            avg_confidence=0,
            errors=["Impossible de lire le PDF"]
        )

    # Determiner les pages a traiter
    if pages is None:
        pages_to_process = list(range(total_pages))
    else:
        pages_to_process = [p for p in pages if 0 <= p < total_pages]

    # Affichage
    filename = os.path.basename(pdf_path)
    print(f"\n{'='*60}")
    print(f"OCR OFFLINE (Donut-base) - DEMARRAGE")
    print(f"{'='*60}")
    print(f"  Fichier: {filename}")
    print(f"  Pages a traiter: {len(pages_to_process)}/{total_pages}")
    print(f"{'‚îÄ'*60}")

    _log.info(f"[OFFLINE-OCR] Demarrage: {len(pages_to_process)}/{total_pages} pages")

    page_results: List[OCRResult] = []
    errors: List[str] = []
    all_texts: List[str] = []

    for i, page_num in enumerate(pages_to_process):
        page_start = time.time()

        # Callback de progression
        if progress_cb:
            progress = (i + 1) / len(pages_to_process)
            progress_cb(progress, f"OCR page {page_num + 1}/{total_pages}")

        _log.info(f"[OFFLINE-OCR] Page {page_num + 1}/{total_pages}...")

        # Convertir la page en image
        image_bytes = pdf_page_to_image(pdf_path, page_num, dpi=dpi, log=_log)

        if not image_bytes:
            error_msg = f"Erreur conversion page {page_num + 1}"
            errors.append(error_msg)
            page_results.append(OCRResult(
                page_number=page_num + 1,
                text="",
                confidence=0.0,
                processing_time=time.time() - page_start,
                error=error_msg
            ))
            continue

        # OCR offline
        text, confidence = ocr_image_offline(image_bytes, log=_log)

        processing_time = time.time() - page_start

        if text:
            all_texts.append(f"--- Page {page_num + 1} ---\n{text}")
            page_results.append(OCRResult(
                page_number=page_num + 1,
                text=text,
                confidence=confidence,
                processing_time=processing_time
            ))
            _log.info(
                f"[OFFLINE-OCR] Page {page_num + 1}: {len(text)} chars, "
                f"confiance={confidence:.0%}, temps={processing_time:.1f}s"
            )
        else:
            error_msg = f"OCR echoue page {page_num + 1}"
            errors.append(error_msg)
            page_results.append(OCRResult(
                page_number=page_num + 1,
                text="",
                confidence=0.0,
                processing_time=processing_time,
                error=error_msg
            ))

    # Statistiques
    total_time = time.time() - start_time
    processed_pages = sum(1 for r in page_results if r.text)
    confidences = [r.confidence for r in page_results if r.confidence > 0]
    avg_confidence = sum(confidences) / len(confidences) if confidences else 0.0

    # Assembler le texte complet
    full_text = "\n\n".join(all_texts)

    # Affichage final
    print(f"{'‚îÄ'*60}")
    print(f"OCR OFFLINE TERMINE")
    print(f"  Pages traitees: {processed_pages}/{len(pages_to_process)}")
    print(f"  Confiance moyenne: {avg_confidence:.0%}")
    print(f"  Temps total: {total_time:.1f}s")
    print(f"{'='*60}\n")

    return DocumentOCRResult(
        total_pages=total_pages,
        processed_pages=processed_pages,
        full_text=full_text,
        page_results=page_results,
        total_time=total_time,
        avg_confidence=avg_confidence,
        errors=errors
    )


def smart_ocr_auto(
    pdf_path: str,
    quality_threshold: float = 0.5,
    fallback_pages_only: bool = True,
    progress_cb: Optional[Callable[[float, str], None]] = None,
    force_offline: bool = False,
    log=None
) -> Dict[str, Any]:
    """
    OCR intelligent avec selection automatique online/offline.

    Detecte le mode actuel et utilise:
    - Mode OFFLINE: Donut-base local
    - Mode ONLINE: DALLEM Vision API

    Args:
        pdf_path: Chemin du PDF
        quality_threshold: Seuil de qualite (0-1)
        fallback_pages_only: Si True, ne traite que les pages de mauvaise qualite
        progress_cb: Callback de progression
        force_offline: Si True, force le mode offline
        log: Logger

    Returns:
        Dict avec texte et metadonnees
    """
    _log = log or logger

    # Determiner le mode
    offline_mode = force_offline or (CONFIG_MANAGER_AVAILABLE and is_offline_mode())

    if offline_mode and OFFLINE_OCR_AVAILABLE:
        _log.info("[OCR] Mode OFFLINE actif - utilisation Donut-base local")

        # Utiliser l'OCR offline
        result = ocr_pdf_offline(
            pdf_path=pdf_path,
            progress_cb=progress_cb,
            log=_log
        )

        return {
            "text": result.full_text,
            "method": "offline_donut",
            "quality_score": result.avg_confidence,
            "llm_ocr_used": True,
            "llm_ocr_confidence": result.avg_confidence,
            "pages_ocr": result.processed_pages,
            "total_pages": result.total_pages,
            "ocr_time": result.total_time,
            "ocr_errors": result.errors,
            "offline_mode": True,
        }

    # Mode online
    if DALLEM_CONFIG_AVAILABLE:
        _log.info("[OCR] Mode ONLINE - utilisation DALLEM Vision")
        return smart_ocr_with_dallem(
            pdf_path=pdf_path,
            quality_threshold=quality_threshold,
            fallback_pages_only=fallback_pages_only,
            progress_cb=progress_cb,
            log=_log
        )

    # Aucun mode disponible
    _log.error("[OCR] Aucun mode OCR disponible (ni offline ni online)")
    return {
        "text": "",
        "method": "none",
        "error": "Aucun mode OCR disponible",
    }


def check_ocr_available() -> Dict[str, bool]:
    """
    Verifie la disponibilite des modes OCR.

    Returns:
        Dict avec statut de chaque mode
    """
    return {
        "online": DALLEM_CONFIG_AVAILABLE,
        "offline": OFFLINE_OCR_AVAILABLE,
        "current_mode": "offline" if (CONFIG_MANAGER_AVAILABLE and is_offline_mode()) else "online",
    }
